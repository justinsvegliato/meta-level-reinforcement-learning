{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80033cea-eced-4242-b57e-a110900a8b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.6)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.21.2-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (9.1.0)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.8.12-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.5/208.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.9.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.2->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Installing collected packages: tifffile, PyWavelets, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.3.0 imageio-2.21.2 scikit-image-0.19.3 tifffile-2022.8.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19fbe84f-e072-4fb9-a8c4-62f489715d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec7964e-d9a3-4ce8-81fc-aad2d252d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f30dc3b-b2e3-45ab-ad0c-02b355c2f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1024, 768)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.init()\n",
    "pygame.display.list_modes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3333028-1688-4fe6-89b7-69ee10e2cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a264d48-9f00-46ff-ba7c-98731daf0686",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_maze_env\n",
      "File \u001b[0;32m/tf/mlrl/mlrl/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaze_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/tf/mlrl/mlrl/maze_env.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDL_VIDEODRIVER\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from mlrl import make_maze_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78927233-435c-4b62-9b3b-4fe96bb1a5ed",
   "metadata": {},
   "source": [
    "## Training Q-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3359e08-b7a8-4b03-a19b-ec6e6d4b670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1272457a-df19-4312-abfa-c83c7839a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ede1104-06c9-4c84-abb3-99cb50da61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(obs_shape, num_actions):\n",
    "    model = tf.keras.Sequential()    \n",
    "    model.add(tf.keras.layers.Dense(24, activation='relu', input_shape=obs_shape))\n",
    "    model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(num_actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8676d44-f929-4471-975a-c1d6ba7beb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_env = tf_py_environment.TFPyEnvironment(tf_agents.environments.gym_wrapper.GymWrapper(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc797334-68ce-44a6-9e50-e6da355d8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(tf_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b5b3914-f882-47f1-9bfd-7c515a517a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep Specs: TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': BoundedTensorSpec(shape=(2,), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(9)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "Action Specs: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(3))\n"
     ]
    }
   ],
   "source": [
    "print(\"TimeStep Specs:\", tf_env.time_step_spec())\n",
    "print(\"Action Specs:\", tf_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1adb5b26-4041-46a1-8b05-2c9e52460530",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a70dbb0-524d-40f7-a03b-4abd9d20f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(),\n",
    "                                                tf_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13a95014-4eae-4a15-910b-3747020a68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9a34b6e-3cff-4343-830b-80adc5dd36b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38000032"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(tf_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dad227e2-25f3-40ea-b2c4-c2f658806c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:253: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if policy_state is ():  # pylint: disable=literal-comparison\n",
      "/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if not (policy_state is None or policy_state is () or policy_state is []):  # pylint: disable=literal-comparison\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_avg_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mcompute_avg_return\u001b[0;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[1;32m      7\u001b[0m episode_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_step\u001b[38;5;241m.\u001b[39mis_last():\n\u001b[0;32m---> 10\u001b[0m     action_step \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     time_step \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mstep(action_step\u001b[38;5;241m.\u001b[39maction)\n\u001b[1;32m     12\u001b[0m     episode_return \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mreward\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:324\u001b[0m, in \u001b[0;36mTFPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    323\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 324\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43maction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip_action\u001b[39m(action, action_spec):\n\u001b[1;32m    327\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action_spec, tensor_spec\u001b[38;5;241m.\u001b[39mBoundedTensorSpec):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/utils/common.py:188\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m check_tf1_allowed()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:561\u001b[0m, in \u001b[0;36mTFPolicy._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    560\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution(time_step, policy_state)  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreparameterized_sampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memit_log_probability:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/policies/tf_policy.py:562\u001b[0m, in \u001b[0;36mTFPolicy._action.<locals>.<lambda>\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    559\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    560\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution(time_step, policy_state)  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    561\u001b[0m actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d: \u001b[43mreparameterized_sampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    563\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39maction)\n\u001b[1;32m    564\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memit_log_probability:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/distributions/reparameterized_sampling.py:50\u001b[0m, in \u001b[0;36msample\u001b[0;34m(distribution, reparam, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mconvert_to_one_hot(samples)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/distribution.py:1234\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/distribution.py:1211\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1207\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1208\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1209\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1210\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1211\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1215\u001b[0m     samples)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/deterministic.py:157\u001b[0m, in \u001b[0;36m_BaseDeterministic._sample_n\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m seed  \u001b[38;5;66;03m# unused\u001b[39;00m\n\u001b[1;32m    156\u001b[0m loc \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m              \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py:851\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(input, shape, name)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    850\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBroadcastTo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compute_avg_return(tf_env, agent.policy, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43984604-d244-462e-8f8a-59ffe56ae728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverb\n",
    "\n",
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "253ca540-d175-4ba9-94a8-9a7791e38d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = replay_buffer.as_dataset(\n",
    "#     num_parallel_calls=3,\n",
    "#     sample_batch_size=batch_size,\n",
    "#     num_steps=2).prefetch(3)\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d9b16e2-04c4-4e1b-9160-48725495a487",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collect_driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcollect_driver\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collect_driver' is not defined"
     ]
    }
   ],
   "source": [
    "collect_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fc8a9f0-c77b-4609-ab2f-e5ea099c795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1783a42-de65-48cc-9cf0-73770dd069a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m agent\u001b[38;5;241m.\u001b[39mtrain_step_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluate the agent's policy once before training.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m avg_return \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_avg_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_eval_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m returns \u001b[38;5;241m=\u001b[39m [avg_return]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Reset the environment.\u001b[39;00m\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mcompute_avg_return\u001b[0;34m(environment, policy, num_episodes)\u001b[0m\n\u001b[1;32m      6\u001b[0m time_step \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      7\u001b[0m episode_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     action_step \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39maction(time_step)\n\u001b[1;32m     11\u001b[0m     time_step \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mstep(action_step\u001b[38;5;241m.\u001b[39maction)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tf_agents/trajectories/time_step.py:89\u001b[0m, in \u001b[0;36mTimeStep.is_last\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_last\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m types\u001b[38;5;241m.\u001b[39mBool:\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_type):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStepType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLAST\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mequal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_type, StepType\u001b[38;5;241m.\u001b[39mLAST)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py:1923\u001b[0m, in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.equal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mequal\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1893\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the truth value of (x == y) element-wise.\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m \n\u001b[1;32m   1895\u001b[0m \u001b[38;5;124;03m  Performs a [broadcast](\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;124;03m    `tf.errors.InvalidArgumentError`: If shapes of arguments are incompatible\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py:3301\u001b[0m, in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3300\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3301\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3302\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEqual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mincompatible_shape_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3303\u001b[0m \u001b[43m      \u001b[49m\u001b[43mincompatible_shape_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3305\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(tf_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    tf_env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "    time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(tf_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe250c-6a9c-44a9-88e4-24998f429255",
   "metadata": {},
   "source": [
    "## Search-Amplified Object-level Q-Value Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "211b495d-ac71-4816-ac1e-51094a3585b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b9a7dda7-8e4a-4edf-a47c-3a0b0bfd6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSearchBasedQEstimator:\n",
    "    \"\"\"\n",
    "        Assumes a deterministic environment and only uses child nodes to compute Q-values\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, goal_state: np.array, n_actions: int = 4, discount: float = 0.99):\n",
    "        self.n_actions = n_actions\n",
    "        self.discount = discount\n",
    "        self.goal_state = goal_state\n",
    "    \n",
    "    def compute_q(self, search_tree_node: SearchTreeNode, action: int) -> float:\n",
    "        children = search_tree_node.get_children()\n",
    "        if action in children:\n",
    "            child_node = children[action][0]\n",
    "            action_taken, reward, next_state = child_node.get_trajectory()\n",
    "            return reward + self.discount * self.compute_value(child_node)\n",
    "        np.abs(env.state - env.maze_view.goal).sum()\n",
    "        return 0\n",
    "        \n",
    "    def compute_value(self, search_tree_node: SearchTreeNode) -> float:\n",
    "        return max(self.compute_q(search_tree_node, action) for action in range(self.n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "65fec030-df13-4a41-97d8-75bc893d42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_est = SimpleSearchBasedQEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "37315a43-b3ed-41c7-90e2-a9a2b7cfcbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_est.compute_value(search_tree.get_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f9634f8a-e3af-4780-b727-4d5978a91ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d5101e0c-58cd-4a38-8a3f-5ee61eb8344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
