Meta-level Policy,Run ID,wandb_version,eval_interval,num_iterations,eval_steps,policy_save_interval,collect_steps,summary_interval,train_num_steps,train_batch_size,env_batch_size,num_learn_samples,root_dir,gpus,n_collect_envs,n_eval_envs,n_video_envs,expand_all_actions,max_tree_size,meta_discount,meta_time_limit,seed,computational_rewards,max_cost_of_computation,finish_on_terminate,min_train_computation_steps,object_discount,agent,transformer_d_model,transformer_n_layers,transformer_n_heads,n_lstm_layers,pretrained_percentile,pretrained_run,pretrained_runs_folder,object_level_config,_wandb,min_computational_steps,action_repeats,agent_name,collect_steps_per_iteration,discount,env,epsilon,epsilon_decay_steps,epsilon_schedule,experience_batch_size,final_epsilon,frame_stack,grayscale,initial_collect_steps,initial_epsilon,learning_rate,max_epochs,metrics,model_config,name,optimiser_config,procgen_env_name,replay_buffer_capacity,run_dir,target_network_update_period,train_steps_per_epoch,video_seconds,pretrained_epoch,pretrained_return,pretrained_path,EvalRewrittenAverageReturn,EvalNumberOfEpisodes,EvalEnvironmentSteps,EvalAverageReturn,EvalAverageEpisodeLength,EvalTime,ObjectLevelMeanReward,ObjectLevelMeanStepsPerEpisode,ObjectLevelEpisodes,ObjectLevelCurrentEpisodeReturn,ObjectLevelCurrentEpisodeSteps
Learned Meta-Policy,zbrgnhev/dry-salad-297,1,15,2000,1000,1,4096,1000,64,32,64,10,outputs/runs/ppo_run_06-55-11-09-05-2023/,,64,64,12,True,64,0.99,500,0,True,0.002,True,5,0.99,ppo,16,2,3,0,0.1,run-16823527592836354,runs,"{'action_repeats': 4, 'agent_name': 'categorical_dqn_agent', 'collect_steps_per_iteration': 1, 'discount': 0.999, 'env': 'bigfish', 'epsilon': 0.1, 'epsilon_decay_steps': 250000, 'epsilon_schedule': False, 'eval_steps': 1000, 'experience_batch_size': 64, 'final_epsilon': 0.1, 'frame_stack': 0, 'grayscale': False, 'initial_collect_steps': 500, 'initial_epsilon': 1.0, 'learning_rate': 0.00025, 'max_epochs': 500, 'metrics': [], 'model_config': 'N/A', 'n_collect_envs': 64, 'n_eval_envs': 64, 'n_video_envs': 12, 'name': 'run', 'optimiser_config': {'amsgrad': False, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'learning_rate': 0.0002500000118743628, 'name': 'Adam'}, 'procgen_env_name': 'bigfish', 'replay_buffer_capacity': 1024, 'run_dir': './runs/categorical_dqn_agent/run-16823527592836354', 'target_network_update_period': 10000, 'train_steps_per_epoch': 20000, 'video_seconds': 60, 'pretrained_epoch': 3, 'pretrained_return': 8.517398, 'pretrained_run': 'run-16823527592836354', 'pretrained_path': 'runs/categorical_dqn_agent/run-16823527592836354/model_weights/sequential_best_3_8.517398', 'pretrained_percentile': 0.1}","{'python_version': '3.8.10', 'cli_version': '0.15.0', 'framework': 'keras', 'is_jupyter_run': False, 'is_kaggle_kernel': False, 'start_time': 1683633357.182088, 't': {1: [2, 3, 55], 2: [2, 3, 55], 3: [2, 16, 23], 4: '3.8.10', 5: '0.15.0', 8: [5]}}",10,4,categorical_dqn_agent,1,0.999,bigfish,0.1,250000,False,64,0.1,0,False,500,1.0,0.00025,500,[],N/A,run,"{'amsgrad': False, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'learning_rate': 0.0002500000118743628, 'name': 'Adam'}",bigfish,1024,./runs/categorical_dqn_agent/run-16823527592836354,10000,20000,60,3,8.517398,runs/categorical_dqn_agent/run-16823527592836354/model_weights/sequential_best_3_8.517398,0.83242863,8662,77031,1.0087451,9.0,6468.1642973423,85.55,432.9,20,0.0,0.0
